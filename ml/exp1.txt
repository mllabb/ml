import pandas as pd
import numpy as np

# Define the dataset
data = pd.DataFrame(pd.read_csv("/content/play_tennis.csv"))

# Compute entropy
def entropy(column):
    counts = column.value_counts()
    probabilities = counts / len(column)
    return -np.sum(probabilities * np.log2(probabilities))

# Compute information gain
def information_gain(data, feature, target):
    total_entropy = entropy(data[target])
    feature_entropy = 0
    for value in data[feature].unique():
        subset = data[data[feature] == value]
        feature_entropy += (len(subset) / len(data)) * entropy(subset[target])
    return total_entropy - feature_entropy

# Find the best feature
def best_feature(data, features, target):
    gains = {feature: information_gain(data, feature, target) for feature in features}
    return max(gains, key=gains.get)

# Build the decision tree
def build_tree(data, features, target):
    classes = data[target].unique()
    if len(classes) == 1:  # All samples belong to one class
        return classes[0]
    if not features:  # No more features to split
        return data[target].mode()[0]

    best = best_feature(data, features, target)
    tree = {best: {}}
    for value in data[best].unique():
        subset = data[data[best] == value]
        new_features = [f for f in features if f != best]
        tree[best][value] = build_tree(subset, new_features, target)
    return tree

# Build the decision tree
features = ['outlook', 'temp', 'humidity', 'wind']
target = 'play'
decision_tree = build_tree(data, features, target)
print("Decision Tree:")
print(decision_tree)

# Classify a new sample
def classify(tree, sample):
    if not isinstance(tree, dict):  # Leaf node
        return tree
    feature = list(tree.keys())[0]
    feature_value = sample[feature]
    subtree = tree[feature].get(feature_value)
    if subtree is None:  # Handle missing branches
        return None
    return classify(subtree, sample)

# Example classification
new_sample = {'outlook': 'Sunny', 'temp': 'Cool', 'humidity': 'High', 'wind': False}
classification = classify(decision_tree, new_sample)
print(f"Classification for new sample: {classification}")
